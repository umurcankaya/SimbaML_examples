{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iQ89A_taIm3"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# GluonTS imports\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.dataset.split import split\n",
    "\n",
    "# SimbaML imports\n",
    "from simba_ml.simulation import distributions, generators\n",
    "from simba_ml.simulation import kinetic_parameters as kinetic_parameters_module\n",
    "from simba_ml.simulation import noisers\n",
    "from simba_ml.simulation import species, system_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2020-02-20')\n",
    "offset = 22\n",
    "\n",
    "prediction_length = 7\n",
    "context_length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "bncUW1E6b90i",
    "outputId": "2bf997d8-b517-4902-b5b9-de24580c9a65"
   },
   "outputs": [],
   "source": [
    "name = \"SIR - Covid-19 - Data Augmentation\"\n",
    "# Population obtained form:\n",
    "# https://www-genesis.destatis.de/genesis/online?operation=abruftabelleBearbeiten&levelindex=1&levelid=1676991208921&auswahloperation=abruftabelleAuspraegungAuswaehlen&auswahlverzeichnis=ordnungsstruktur&auswahlziel=werteabruf&code=12411-0001&auswahltext=&werteabruf=Value+retrieval#abreadcrumb\n",
    "specieses = [\n",
    "    species.Species(\"Suspectible\", distributions.Constant(83166711-100), contained_in_output=False, min_value=0), #83166711\n",
    "    species.Species(\"Infected\", distributions.Constant(100), contained_in_output=False, min_value=0),\n",
    "    species.Species(\"Recovered\", distributions.Constant(0), contained_in_output=False, min_value=0),\n",
    "    species.Species(\"Cumulative Infected\", distributions.Constant(100), contained_in_output=True, min_value=0),\n",
    "]\n",
    "\n",
    "kinetic_parameters: dict[str, kinetic_parameters_module.KineticParameter] = {\n",
    "    \"beta\": kinetic_parameters_module.ConstantKineticParameter(distributions.ContinuousUniformDistribution(0.32, 0.35)),\n",
    "    \"gamma\": kinetic_parameters_module.ConstantKineticParameter(distributions.ContinuousUniformDistribution(0.123, 0.125)),\n",
    "}\n",
    "\n",
    "def deriv(_t: float, y: list[float], arguments: dict[str, float]) -> tuple[float, float, float]:\n",
    "    \"\"\"Defines the derivative of the function at the point _.\n",
    "\n",
    "    Args:\n",
    "        y: Current y vector.\n",
    "        arguments: Dictionary of arguments configuring the problem.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]\n",
    "    \"\"\"\n",
    "    S, I, R, _ = y\n",
    "    N = S + I + R\n",
    "    \n",
    "\n",
    "    dS_dt = -arguments[\"beta\"] * S * I / N\n",
    "    dI_dt = arguments[\"beta\"] * S * I / N - (arguments[\"gamma\"]) * I\n",
    "    dR_dt = arguments[\"gamma\"] * I\n",
    "    dC_dt = arguments[\"beta\"] * S * I / N\n",
    "    return dS_dt, dI_dt, dR_dt, dC_dt\n",
    "\n",
    "\n",
    "\n",
    "noiser = noisers.AdditiveNoiser(distributions.NormalDistribution(0, 42*10**3))\n",
    "\n",
    "sm = system_model.SystemModel(\n",
    "            name,\n",
    "            specieses,\n",
    "            kinetic_parameters,\n",
    "            deriv=deriv,\n",
    "            noiser=noiser,\n",
    "            timestamps=distributions.Constant(100)\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ry-1W5OpeNvt"
   },
   "outputs": [],
   "source": [
    "simulations = generators.TimeSeriesGenerator(sm).generate_signals(n=100)\n",
    "simulations_new_cases = [simulation.assign(new_cases = simulation[\"Cumulative Infected\"].diff()) for simulation in simulations]\n",
    "sim_targets = [{\"target\": simulation[\"new_cases\"].iloc[20:100].to_numpy(), \"start\": start_date} for simulation in simulations_new_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data =  pd.read_csv('data/rki_case_numbers_germany.csv')\n",
    "real_data = real_data.loc[50:150].reset_index(drop=True)\n",
    "real_target = [{\"target\": real_data[\"new_cases_7d_average\"].to_numpy(), \"start\": start_date}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = [{\"target\": real_target[0][\"target\"][:offset], \"start\": start_date}] + sim_targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ListDataset(target, freq='d')\n",
    "real_dataset = ListDataset(real_target, freq='d')\n",
    "\n",
    "train_real, test_gen = split(real_dataset, offset=offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with augmented dataset\n",
    "model = SimpleFeedForwardEstimator(\n",
    "    prediction_length=prediction_length, context_length=context_length,  trainer_kwargs={\"max_epochs\": 30}\n",
    ")\n",
    "predictor = model.train(dataset)\n",
    "\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "forecasts_mix = list(predictor.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with only real-world dataset\n",
    "del model\n",
    "model = SimpleFeedForwardEstimator(\n",
    "    prediction_length=prediction_length, context_length=context_length,  trainer_kwargs={\"max_epochs\": 30}, weight_decay=0.01\n",
    ")\n",
    "predictor = model.train(train_real)\n",
    "\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "forecasts_obs_only = list(predictor.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires pdflatex\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_date = pd.to_datetime(real_data.loc[offset, \"day_idx\"])\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "\n",
    "forecasts_obs_only = list(predictor.predict(test_data.input))\n",
    "\n",
    "medium = 11\n",
    "large = 12\n",
    "\n",
    "plt.rc('font', size=large)         \n",
    "plt.rc('axes', titlesize=large)     \n",
    "plt.rc('axes', labelsize=large)    \n",
    "plt.rc('xtick', labelsize=medium)   \n",
    "plt.rc('ytick', labelsize=medium)    \n",
    "plt.rc('legend', fontsize=large)   \n",
    "plt.rc('figure', titlesize=large)  \n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.8, 4.8)\n",
    "\n",
    "\n",
    "# Plot groud truth time series\n",
    "real_data[\"day_idx\"] = pd.to_datetime(real_data[\"day_idx\"])\n",
    "ax1 = plt.plot(real_data[\"day_idx\"][:offset+prediction_length+1], real_data[\"new_cases_7d_average\"][:offset+prediction_length+1],\n",
    "               label=\"Ground Truth\", color=\"#332288\", linewidth=2.5)\n",
    "\n",
    "# Plot forecast of model trained with augmented dataset\n",
    "fcoo = forecasts_mix[0].to_sample_forecast(num_samples=10000)\n",
    "fcoo.start_date = forecast_date\n",
    "\n",
    "fcoo.samples = np.array([[real_data['new_cases_7d_average'][offset]] + list(a) for a in fcoo.samples])\n",
    "fcoo.plot( prediction_intervals= (50, 85), color=\"#44AA99\");\n",
    "\n",
    "# Plot forecast of model trained with only the real-world dataset\n",
    "fcoo = forecasts_obs_only[0].to_sample_forecast(num_samples=10000)\n",
    "fcoo.start_date = forecast_date\n",
    "\n",
    "fcoo.samples = np.array([[real_data['new_cases_7d_average'][offset]] + list(a) for a in fcoo.samples])\n",
    "fcoo.plot( prediction_intervals= (50, 85), color=\"#AA4499\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set correct legend\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "new_handles = [handles[0]]\n",
    "new_labels = [labels[0]]\n",
    "first = True\n",
    "for handle, label in zip(handles[1:], labels[1:]):\n",
    "    if \"%\" not in label:\n",
    "        new_handles.append(handle)\n",
    "        if first:\n",
    "            new_labels.append(\"Forecast: Synthetically Augmented Data\")\n",
    "\n",
    "            first = False\n",
    "        else:\n",
    "            new_labels.append(\"Forecast: Only Real Data\")\n",
    "\n",
    "\n",
    "ax.legend(new_handles, new_labels, loc=\"upper left\", fontsize=\"medium\", ncols=1)    \n",
    "\n",
    "# Set ticks\n",
    "tick_dates = pd.date_range(start=\"2020-02-22\", periods=offset+prediction_length, freq=\"D\")[::4]\n",
    "ax.set_xticks(tick_dates)\n",
    "\n",
    "tick_labels = [date.strftime('%d\\n%b') for date in tick_dates]\n",
    "ax.set_xticklabels(tick_labels)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\");\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel(\"Date (2020)\", fontsize=\"large\")\n",
    "plt.ylabel(\"New Cases (7-day average)\", fontsize=\"large\")\n",
    "\n",
    "# Add train cutoff visualisation\n",
    "plt.vlines(x=forecast_date, ymin=0, ymax=14000, color=\"black\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(pd.to_datetime('2020-03-12 21:30'), 4500, \"Training cutoff\", fontsize=12, color=\"black\", rotation=90, horizontalalignment='right');\n",
    "\n",
    "# Shade the background of the training data\n",
    "start_date = pd.to_datetime('2020-02-01')\n",
    "end_date = forecast_date\n",
    "ax.axvspan(start_date, end_date, facecolor='grey', alpha=0.14)\n",
    "\n",
    "box = ax.get_position()\n",
    "print(box.height)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(pd.to_datetime('2020-02-20'), pd.to_datetime('2020-03-20'))\n",
    "plt.ylim(0, 12000)\n",
    "\n",
    "\n",
    "plt.savefig('figure2.pdf', bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c43c9f1afee0aec6f6402289c8f40483170b785f95b15918734a3bc4639e76e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
