{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7iQ89A_taIm3"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# GluonTS imports\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.simple_feedforward import SimpleFeedForwardEstimator\n",
    "from gluonts.dataset.split import split\n",
    "\n",
    "# SimbaML imports\n",
    "from simba_ml.simulation import distributions, generators\n",
    "from simba_ml.simulation import kinetic_parameters as kinetic_parameters_module\n",
    "from simba_ml.simulation import noisers\n",
    "from simba_ml.simulation import species, system_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2020-02-20')\n",
    "offset = 22\n",
    "\n",
    "prediction_length = 7\n",
    "context_length = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "bncUW1E6b90i",
    "outputId": "2bf997d8-b517-4902-b5b9-de24580c9a65"
   },
   "outputs": [],
   "source": [
    "name = \"SIR - Covid-19 - Data Augmentation\"\n",
    "# Population obtained form:\n",
    "# https://www-genesis.destatis.de/genesis/online?operation=abruftabelleBearbeiten&levelindex=1&levelid=1676991208921&auswahloperation=abruftabelleAuspraegungAuswaehlen&auswahlverzeichnis=ordnungsstruktur&auswahlziel=werteabruf&code=12411-0001&auswahltext=&werteabruf=Value+retrieval#abreadcrumb\n",
    "specieses = [\n",
    "    species.Species(\"Suspectible\", distributions.Constant(83166711-100), contained_in_output=False, min_value=0), #83166711\n",
    "    species.Species(\"Infected\", distributions.Constant(100), contained_in_output=False, min_value=0),\n",
    "    species.Species(\"Recovered\", distributions.Constant(0), contained_in_output=False, min_value=0),\n",
    "    species.Species(\"Cumulative Infected\", distributions.Constant(100), contained_in_output=True, min_value=0),\n",
    "]\n",
    "\n",
    "kinetic_parameters: dict[str, kinetic_parameters_module.KineticParameter] = {\n",
    "    \"beta\": kinetic_parameters_module.ConstantKineticParameter(distributions.ContinuousUniformDistribution(0.32, 0.35)),\n",
    "    \"gamma\": kinetic_parameters_module.ConstantKineticParameter(distributions.ContinuousUniformDistribution(0.123, 0.125)),\n",
    "}\n",
    "\n",
    "def deriv(_t: float, y: list[float], arguments: dict[str, float]) -> tuple[float, float, float]:\n",
    "    \"\"\"Defines the derivative of the function at the point _.\n",
    "\n",
    "    Args:\n",
    "        y: Current y vector.\n",
    "        arguments: Dictionary of arguments configuring the problem.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float]\n",
    "    \"\"\"\n",
    "    S, I, R, _ = y\n",
    "    N = S + I + R\n",
    "    \n",
    "\n",
    "    dS_dt = -arguments[\"beta\"] * S * I / N\n",
    "    dI_dt = arguments[\"beta\"] * S * I / N - (arguments[\"gamma\"]) * I\n",
    "    dR_dt = arguments[\"gamma\"] * I\n",
    "    dC_dt = arguments[\"beta\"] * S * I / N\n",
    "    return dS_dt, dI_dt, dR_dt, dC_dt\n",
    "\n",
    "\n",
    "\n",
    "noiser = noisers.AdditiveNoiser(distributions.NormalDistribution(0, 42*10**3))\n",
    "\n",
    "sm = system_model.SystemModel(\n",
    "            name,\n",
    "            specieses,\n",
    "            kinetic_parameters,\n",
    "            deriv=deriv,\n",
    "            noiser=noiser,\n",
    "            timestamps=distributions.Constant(100)\n",
    "        )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ry-1W5OpeNvt"
   },
   "outputs": [],
   "source": [
    "simulations = generators.TimeSeriesGenerator(sm).generate_signals(n=100)\n",
    "simulations_new_cases = [simulation.assign(new_cases = simulation[\"Cumulative Infected\"].diff()) for simulation in simulations]\n",
    "sim_targets = [{\"target\": simulation[\"new_cases\"].iloc[20:100].to_numpy(), \"start\": start_date} for simulation in simulations_new_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data =  pd.read_csv('data/rki_case_numbers_germany.csv')\n",
    "real_data = real_data.loc[50:150].reset_index(drop=True)\n",
    "real_target = [{\"target\": real_data[\"new_cases_7d_average\"].to_numpy(), \"start\": start_date}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = [{\"target\": real_target[0][\"target\"][:offset], \"start\": start_date}] + sim_targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ListDataset(target, freq='d')\n",
    "real_dataset = ListDataset(real_target, freq='d')\n",
    "\n",
    "train_real, test_gen = split(real_dataset, offset=offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainingDataset' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_real\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingDataset' object has no attribute 'plot'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/umurcankaya/anaconda3/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type                   | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model | SimpleFeedForwardModel | 3.2 K  | train\n",
      "---------------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6b7b2df6504af381b7fb0eb1080a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 15.91741 (best 15.91741), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 15.22418 (best 15.22418), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 14.82530 (best 14.82530), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' was not in top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 14.75086 (best 14.75086), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 14.09575 (best 14.09575), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 13.98742 (best 13.98742), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 13.80242 (best 13.80242), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' was not in top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' was not in top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 13.78148 (best 13.78148), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' was not in top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' reached 13.70510 (best 13.70510), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=14-step=750.ckpt' as top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 13.61501 (best 13.61501), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_2/checkpoints/epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' was not in top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training with augmented dataset\n",
    "model = SimpleFeedForwardEstimator(\n",
    "    prediction_length=prediction_length, context_length=context_length,  trainer_kwargs={\"max_epochs\": 30}\n",
    ")\n",
    "predictor = model.train(dataset)\n",
    "\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "forecasts_mix = list(predictor.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type                   | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | model | SimpleFeedForwardModel | 3.2 K  | train\n",
      "---------------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473c13af573f4686a92da8e79a968dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 11.35503 (best 11.35503), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 8.45071 (best 8.45071), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 7.89309 (best 7.89309), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 7.49804 (best 7.49804), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 7.08806 (best 7.08806), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 6.81951 (best 6.81951), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 6.76612 (best 6.76612), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 6.56997 (best 6.56997), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 6.45588 (best 6.45588), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' was not in top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 6.10567 (best 6.10567), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' reached 6.09235 (best 6.09235), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=11-step=600.ckpt' as top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 6.04445 (best 6.04445), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' was not in top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' was not in top 1\n",
      "Epoch 16, global step 850: 'train_loss' was not in top 1\n",
      "Epoch 17, global step 900: 'train_loss' was not in top 1\n",
      "Epoch 18, global step 950: 'train_loss' was not in top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 6.03949 (best 6.03949), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' was not in top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' was not in top 1\n",
      "Epoch 24, global step 1250: 'train_loss' reached 5.92324 (best 5.92324), saving model to '/Users/umurcankaya/Library/Mobile Documents/com~apple~CloudDocs/PhD/Act-i-ML/Scripts/SimbaML_examples/src/covid_data_augmentation/lightning_logs/version_3/checkpoints/epoch=24-step=1250.ckpt' as top 1\n",
      "Epoch 25, global step 1300: 'train_loss' was not in top 1\n",
      "Epoch 26, global step 1350: 'train_loss' was not in top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' was not in top 1\n",
      "Epoch 29, global step 1500: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "# Training with only real-world dataset\n",
    "del model\n",
    "model = SimpleFeedForwardEstimator(\n",
    "    prediction_length=prediction_length, context_length=context_length,  trainer_kwargs={\"max_epochs\": 30}, weight_decay=0.01\n",
    ")\n",
    "predictor = model.train(train_real)\n",
    "\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "forecasts_obs_only = list(predictor.predict(test_data.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires pdflatex\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "forecast_date = pd.to_datetime(real_data.loc[offset, \"day_idx\"])\n",
    "test_data = test_gen.generate_instances(prediction_length=prediction_length, windows=1)\n",
    "\n",
    "forecasts_obs_only = list(predictor.predict(test_data.input))\n",
    "\n",
    "medium = 11\n",
    "large = 12\n",
    "\n",
    "plt.rc('font', size=large)         \n",
    "plt.rc('axes', titlesize=large)     \n",
    "plt.rc('axes', labelsize=large)    \n",
    "plt.rc('xtick', labelsize=medium)   \n",
    "plt.rc('ytick', labelsize=medium)    \n",
    "plt.rc('legend', fontsize=large)   \n",
    "plt.rc('figure', titlesize=large)  \n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6.8, 4.8)\n",
    "\n",
    "# Plot groud truth time series\n",
    "real_data[\"day_idx\"] = pd.to_datetime(real_data[\"day_idx\"])\n",
    "ax1 = plt.plot(real_data[\"day_idx\"][:offset+prediction_length+1], real_data[\"new_cases_7d_average\"][:offset+prediction_length+1],\n",
    "               label=\"Ground Truth\", color=\"#332288\", linewidth=2.5)\n",
    "\n",
    "# Plot forecast of model trained with augmented dataset\n",
    "fcoo = forecasts_mix[0].to_sample_forecast(num_samples=10000)\n",
    "fcoo.start_date = forecast_date\n",
    "fcoo.start_date.freq = \"D\"\n",
    "\n",
    "fcoo.samples = np.array([[real_data['new_cases_7d_average'][offset]] + list(a) for a in fcoo.samples])\n",
    "fcoo.plot(intervals=[0.5, 0.85], color=\"#44AA99\");\n",
    "\n",
    "# Plot forecast of model trained with only the real-world dataset\n",
    "fcoo = forecasts_obs_only[0].to_sample_forecast(num_samples=10000)\n",
    "fcoo.start_date = forecast_date\n",
    "fcoo.start_date.freq = \"D\"\n",
    "\n",
    "fcoo.samples = np.array([[real_data['new_cases_7d_average'][offset]] + list(a) for a in fcoo.samples])\n",
    "fcoo.plot(intervals=[0.5, 0.85], color=\"#AA4499\");  \n",
    "\n",
    "\n",
    "# Set correct legend\n",
    "ax = plt.gca()\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "new_handles = [handles[0]]\n",
    "new_labels = [labels[0]]\n",
    "first = True\n",
    "for handle, label in zip(handles[1:], labels[1:]):\n",
    "    if \"%\" not in label:\n",
    "        new_handles.append(handle)\n",
    "        if first:\n",
    "            new_labels.append(\"Forecast: Synthetically Augmented Data\")\n",
    "\n",
    "            first = False\n",
    "        else:\n",
    "            new_labels.append(\"Forecast: Only Real Data\")\n",
    "\n",
    "\n",
    "ax.legend(new_handles, new_labels, loc=\"upper left\", fontsize=\"medium\", ncols=1)    \n",
    "\n",
    "# Set ticks\n",
    "tick_dates = pd.date_range(start=\"2020-02-22\", periods=offset+prediction_length, freq=\"D\")[::4]\n",
    "ax.set_xticks(tick_dates)\n",
    "\n",
    "tick_labels = [date.strftime('%d\\n%b') for date in tick_dates]\n",
    "ax.set_xticklabels(tick_labels)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\");\n",
    "\n",
    "# Set axis labels\n",
    "plt.xlabel(\"Date (2020)\", fontsize=\"large\")\n",
    "plt.ylabel(\"New Cases (7-day average)\", fontsize=\"large\")\n",
    "\n",
    "# Add train cutoff visualisation\n",
    "plt.vlines(x=forecast_date, ymin=0, ymax=14000, color=\"black\", linestyle=\"dashed\", linewidth=1)\n",
    "plt.text(pd.to_datetime('2020-03-12 21:30'), 4500, \"Training cutoff\", fontsize=12, color=\"black\", rotation=90, horizontalalignment='right');\n",
    "\n",
    "# Shade the background of the training data\n",
    "start_date = pd.to_datetime('2020-02-01')\n",
    "end_date = forecast_date\n",
    "ax.axvspan(start_date, end_date, facecolor='grey', alpha=0.14)\n",
    "\n",
    "box = ax.get_position()\n",
    "print(box.height)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(pd.to_datetime('2020-02-20'), pd.to_datetime('2020-03-20'))\n",
    "plt.ylim(0, 12000)\n",
    "\n",
    "\n",
    "plt.savefig('figure2.pdf', bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.get_legend_handles_labels()\n",
    "for handle, label in zip(handles[1:], labels[1:]):\n",
    "    print(handle, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x31f175310>], ['Ground Truth'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
